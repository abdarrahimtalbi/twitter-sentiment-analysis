{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train word2vec locally\n",
    "\n",
    "This allows a smart initialization of our neural net's word embeddings.\n",
    "It seems that initializing the embeddings by training them locally, as opposed to using pre-trained word2vec embeddings (available online) can lead to better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andrei/anaconda3/envs/cil/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN = os.path.join('..', 'train')\n",
    "TEST = os.path.join('..', 'test')\n",
    "POS_TWEET_FILE = os.path.join(TRAIN, 'train_pos_full.txt')\n",
    "NEG_TWEET_FILE = os.path.join(TRAIN, 'train_pos_full.txt')\n",
    "TEST_TWEET_FILE = os.path.join(TEST, 'test_data.txt')\n",
    "EMBEDDING_SIZE = 275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_tweets(fname):\n",
    "    \"\"\"Read the tweets in the given file.\n",
    "    \n",
    "    Returns a 2d array where every row is a tweet, split into words.\n",
    "    \"\"\"\n",
    "    with open(fname, 'r') as f:\n",
    "        return [l.split() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tweets = read_tweets(POS_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_tweets = read_tweets(NEG_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tweets = read_tweets(TEST_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510000\n"
     ]
    }
   ],
   "source": [
    "sentences = pos_tweets + neg_tweets + test_tweets\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download this for testing: https://github.com/arfon/word2vec/blob/master/questions-words.txt\n",
    "# Highly recommended!\n",
    "\n",
    "question_file = \"questions-words.txt\"\n",
    "\n",
    "def eval_embeddings(model):\n",
    "    accuracy_results = model.accuracy(question_file)\n",
    "    summary = accuracy_results[-1]\n",
    "    assert summary['section'] == 'total'\n",
    "    incorrect = summary['incorrect']\n",
    "    correct = summary['correct']\n",
    "\n",
    "    incorrect_n = len(incorrect)\n",
    "    correct_n = len(correct)\n",
    "\n",
    "    acc = correct_n / incorrect_n\n",
    "    return acc, correct_n, incorrect_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKERS = 8\n",
    "# Note: Moises's team uses size=200 as of June 13.\n",
    "# See: https://groups.google.com/forum/#!msg/gensim/ggCHGncd5rU/Z_pQDD69AAAJ\n",
    "# for some parameter hints.\n",
    "model = Word2Vec(sentences, size=EMBEDDING_SIZE, window=10, min_count=5, workers=WORKERS)# , alpha=0.05, cbow_mean=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.4792458415031433),\n",
       " ('alpha', 0.38749757409095764),\n",
       " ('madonna', 0.3621598482131958),\n",
       " ('pageants', 0.353053480386734),\n",
       " ('kenny', 0.3485540747642517),\n",
       " ('goddess', 0.34342798590660095),\n",
       " ('hawk', 0.342306524515152),\n",
       " ('protects', 0.34013429284095764),\n",
       " ('sinner', 0.3393355906009674),\n",
       " ('president', 0.3371276557445526)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be queen\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('croatia', 0.6066615581512451),\n",
       " ('finland', 0.6033172607421875),\n",
       " ('holland', 0.5851148366928101),\n",
       " ('norway', 0.5845724940299988),\n",
       " ('belgium', 0.5838773250579834),\n",
       " ('switzerland', 0.5790820121765137),\n",
       " ('sweden', 0.578895628452301),\n",
       " ('germany', 0.5740625858306885),\n",
       " ('spain', 0.5683605670928955),\n",
       " ('portugal', 0.5624834299087524)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be germany\n",
    "model.most_similar(positive=['france', 'berlin'], negative=['paris'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'syn0': 83779200, 'syn1neg': 83779200, 'total': 202466400, 'vocab': 34908000}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.531663722765\n",
      "0.148042275749\n",
      "0.245260193706\n",
      "0.0137228767854\n"
     ]
    }
   ],
   "source": [
    "# A few more sanity checks\n",
    "print(model.similarity('woman', 'man'))\n",
    "print(model.similarity('woman', 'coffee'))\n",
    "print(model.similarity('woman', 'penis'))\n",
    "print(model.similarity('woman', 'football'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.201689831471\n",
      "0.686243034977\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('car','man'))\n",
    "print(model.similarity('car','truck'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.340 accuracy; Analogies: 2339 correct, 6871 incorrect\n"
     ]
    }
   ],
   "source": [
    "acc, correct_n, incorrect_n = eval_embeddings(model)\n",
    "print(\"{0:5.3f} accuracy; Analogies: {1} correct, {2} incorrect\".format(\n",
    "    acc, correct_n, incorrect_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies (full Twitter data)\n",
    " * Vanilla (size=225, window=5, min_count=5): 0.319 accuracy; Analogies: 2233 correct, 7004 incorrect\n",
    " * (size=300, window=5,  min_count=5): 0.337 accuracy; Analogies: 2329 correct, 6908 incorrect\n",
    " * (size=500, window=5,  min_count=5): 0.330 accuracy; Analogies: 2292 correct, 6945 incorrect\n",
    " * (size=300, window=10, min_count=5): 0.346 accuracy; Analogies: 2374 correct, 6863 incorrect\n",
    " * (size=300, window=15, min_count=5): 0.342 accuracy; Analogies: 2356 correct, 6881 incorrect\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO(andrei): Save the model!\n",
    "fname = \"./word2vec-local-gensim-{0}.bin\".format(EMBEDDING_SIZE)\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Some experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings of size 100...\n",
      "Evaluating embeddings of size 100...\n",
      "Size 100: 0.274 accuracy; Analogies: 1983 correct, 7227 incorrect\n",
      "Computing embeddings of size 150...\n",
      "Evaluating embeddings of size 150...\n",
      "Size 150: 0.317 accuracy; Analogies: 2216 correct, 6994 incorrect\n",
      "Computing embeddings of size 175...\n",
      "Evaluating embeddings of size 175...\n",
      "Size 175: 0.323 accuracy; Analogies: 2246 correct, 6964 incorrect\n",
      "Computing embeddings of size 200...\n",
      "Evaluating embeddings of size 200...\n",
      "Size 200: 0.337 accuracy; Analogies: 2323 correct, 6887 incorrect\n",
      "Computing embeddings of size 225...\n",
      "Evaluating embeddings of size 225...\n",
      "Size 225: 0.336 accuracy; Analogies: 2316 correct, 6894 incorrect\n",
      "Computing embeddings of size 250...\n",
      "Evaluating embeddings of size 250...\n",
      "Size 250: 0.337 accuracy; Analogies: 2319 correct, 6891 incorrect\n",
      "Computing embeddings of size 275...\n",
      "Evaluating embeddings of size 275...\n",
      "Size 275: 0.346 accuracy; Analogies: 2369 correct, 6841 incorrect\n",
      "Computing embeddings of size 300...\n",
      "Evaluating embeddings of size 300...\n",
      "Size 300: 0.348 accuracy; Analogies: 2376 correct, 6834 incorrect\n",
      "Computing embeddings of size 325...\n",
      "Evaluating embeddings of size 325...\n",
      "Size 325: 0.348 accuracy; Analogies: 2378 correct, 6832 incorrect\n",
      "Computing embeddings of size 350...\n",
      "Evaluating embeddings of size 350...\n",
      "Size 350: 0.343 accuracy; Analogies: 2352 correct, 6858 incorrect\n",
      "Computing embeddings of size 375...\n",
      "Evaluating embeddings of size 375...\n",
      "Size 375: 0.336 accuracy; Analogies: 2318 correct, 6892 incorrect\n",
      "Computing embeddings of size 400...\n",
      "Evaluating embeddings of size 400...\n",
      "Size 400: 0.335 accuracy; Analogies: 2309 correct, 6901 incorrect\n"
     ]
    }
   ],
   "source": [
    "emb_sizes = [100, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400]\n",
    "\n",
    "for emb_size in emb_sizes:\n",
    "    print(\"Computing embeddings of size {0}...\".format(emb_size))\n",
    "    model = Word2Vec(sentences, size=emb_size, window=10, min_count=5, workers=WORKERS)\n",
    "    print(\"Evaluating embeddings of size {0}...\".format(emb_size))\n",
    "    acc, correct_n, incorrect_n = eval_embeddings(model)\n",
    "    print(\"Size {3}: {0:5.3f} accuracy; Analogies: {1} correct, {2} incorrect\".format(\n",
    "        acc, correct_n, incorrect_n, emb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
