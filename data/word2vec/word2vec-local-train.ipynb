{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train word2vec locally\n",
    "\n",
    "This allows a smart initialization of our neural net's word embeddings.\n",
    "It seems that initializing the embeddings by training them locally, as opposed to using pre-trained word2vec embeddings (available online) can lead to better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andrei/anaconda3/envs/cil/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN = os.path.join('..', 'train')\n",
    "TEST = os.path.join('..', 'test')\n",
    "POS_TWEET_FILE = os.path.join(TRAIN, 'train_pos_full.txt')\n",
    "NEG_TWEET_FILE = os.path.join(TRAIN, 'train_neg_full.txt')\n",
    "TEST_TWEET_FILE = os.path.join(TEST, 'test_data.txt')\n",
    "EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_tweets(fname):\n",
    "    \"\"\"Read the tweets in the given file.\n",
    "    \n",
    "    Returns a 2d array where every row is a tweet, split into words.\n",
    "    \"\"\"\n",
    "    with open(fname, 'r') as f:\n",
    "        return [l.split() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tweets = read_tweets(POS_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_tweets = read_tweets(NEG_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tweets = read_tweets(TEST_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510000\n"
     ]
    }
   ],
   "source": [
    "sentences = pos_tweets + neg_tweets + test_tweets\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = [item.strip() for sentence in sentences for item in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for Nikos's 1st stage substitutions.\n",
    "assert '<num>' in tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Another sanity check\n",
    "print(len([t for t in tokens if 'bootstrap' == t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download this for testing: https://github.com/arfon/word2vec/blob/master/questions-words.txt\n",
    "# Highly recommended!\n",
    "\n",
    "question_file = \"questions-words.txt\"\n",
    "\n",
    "def eval_embeddings(model):\n",
    "    accuracy_results = model.accuracy(question_file)\n",
    "    summary = accuracy_results[-1]\n",
    "    assert summary['section'] == 'total'\n",
    "    incorrect = summary['incorrect']\n",
    "    correct = summary['correct']\n",
    "\n",
    "    incorrect_n = len(incorrect)\n",
    "    correct_n = len(correct)\n",
    "\n",
    "    acc = correct_n / incorrect_n\n",
    "    return acc, correct_n, incorrect_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKERS = 8\n",
    "# Note: Moises's team uses size=200 as of June 13.\n",
    "# See: https://groups.google.com/forum/#!msg/gensim/ggCHGncd5rU/Z_pQDD69AAAJ\n",
    "# for some parameter hints.\n",
    "model = Word2Vec(sentences, size=EMBEDDING_SIZE, window=10, min_count=5, workers=WORKERS)# , alpha=0.05, cbow_mean=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yet another sanity check.\n",
    "model.vocab['bootstrap'].count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.5664982795715332),\n",
       " ('josephine', 0.4243753254413605),\n",
       " (\"king's\", 0.41293755173683167),\n",
       " ('witch', 0.40765368938446045),\n",
       " ('memoirs', 0.40616926550865173),\n",
       " ('empress', 0.3961029648780823),\n",
       " ('palliser', 0.3934062719345093),\n",
       " ('wealthy', 0.38778430223464966),\n",
       " ('oedipus', 0.38776156306266785),\n",
       " ('geisha', 0.3861485719680786)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be queen\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('finland', 0.6568661332130432),\n",
       " ('germany', 0.6284235715866089),\n",
       " ('croatia', 0.6253992915153503),\n",
       " ('austria', 0.6232521533966064),\n",
       " ('sweden', 0.6187658905982971),\n",
       " ('switzerland', 0.615707516670227),\n",
       " ('belgium', 0.6112383604049683),\n",
       " ('denmark', 0.6090745329856873),\n",
       " ('russia', 0.6063501238822937),\n",
       " ('poland', 0.6030704975128174)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be germany\n",
    "model.most_similar(positive=['france', 'berlin'], negative=['paris'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'syn0': 111271200,\n",
       " 'syn1neg': 111271200,\n",
       " 'total': 268905400,\n",
       " 'vocab': 46363000}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52955911881\n",
      "0.114179236087\n",
      "0.268376207035\n",
      "0.0404427249823\n"
     ]
    }
   ],
   "source": [
    "# A few more sanity checks\n",
    "print(model.similarity('woman', 'man'))\n",
    "print(model.similarity('woman', 'coffee'))\n",
    "print(model.similarity('woman', 'penis'))\n",
    "print(model.similarity('woman', 'football'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.192689974775\n",
      "0.640076543279\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('car','man'))\n",
    "print(model.similarity('car','truck'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.407 accuracy; Analogies: 3053 correct, 7493 incorrect\n"
     ]
    }
   ],
   "source": [
    "acc, correct_n, incorrect_n = eval_embeddings(model)\n",
    "print(\"{0:5.3f} accuracy; Analogies: {1} correct, {2} incorrect\".format(\n",
    "    acc, correct_n, incorrect_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies (full Twitter data)\n",
    " * Vanilla (size=225, window=5, min_count=5): 0.319 accuracy; Analogies: 2233 correct, 7004 incorrect\n",
    " * (size=300, window=5,  min_count=5): 0.337 accuracy; Analogies: 2329 correct, 6908 incorrect\n",
    " * (size=500, window=5,  min_count=5): 0.330 accuracy; Analogies: 2292 correct, 6945 incorrect\n",
    " * (size=300, window=10, min_count=5): 0.346 accuracy; Analogies: 2374 correct, 6863 incorrect\n",
    " * (size=300, window=15, min_count=5): 0.342 accuracy; Analogies: 2356 correct, 6881 incorrect\n",
    " * (size=400, window=10, min_count=5): 0.341 accuracy; Analogies: 2340 correct, 6870 incorrect\n",
    "\n",
    "### Accuracties (full Twitter data + Nikos 1st stage preprocessing)\n",
    " * (size=200, window=10, min_count=5): 0.327 accuracy; Analogies: 2316 correct, 7093 incorrect\n",
    " * (size=225, window=10, min_count=5): 0.331 accuracy; Analogies: 2342 correct, 7067 incorrect\n",
    " * (size=250, window=10, min_count=5): 0.330 accuracy; Analogies: 2336 correct, 7073 incorrect\n",
    " * (size=275, window=10, min_count=5): 0.337 accuracy; Analogies: 2374 correct, 7035 incorrect\n",
    " * (size=300, window=10, min_count=5): 0.334 accuracy; Analogies: 2355 correct, 7054 incorrect\n",
    " * (size=325, window=10, min_count=5): 0.334 accuracy; Analogies: 2356 correct, 7053 incorrect\n",
    " * (size=350, window=10, min_count=5): 0.330 accuracy; Analogies: 2334 correct, 7075 incorrect\n",
    " * (size=400, window=10, min_count=5): 0.321 accuracy; Analogies: 2289 correct, 7120 incorrect\n",
    " \n",
    "### After fixing Andrei's retarded bug\n",
    " * (size=300, window=10, min_count=5): 0.438 accuracy; Analogies: 3071 correct, 7019 incorrect\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimensionality: 300\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding dimensionality: {0}\".format(EMBEDDING_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing embeddings to file ./word2vec-local-gensim-300.bin.\n",
      "Done! Happy neural networking!\n"
     ]
    }
   ],
   "source": [
    "fname = \"./word2vec-local-gensim-{0}.bin\".format(EMBEDDING_SIZE)\n",
    "print(\"Writing embeddings to file {0}.\".format(fname))\n",
    "model.save(fname)\n",
    "print(\"Done! Happy neural networking!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Some experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings of size 225 and window 5...\n"
     ]
    }
   ],
   "source": [
    "emb_sizes = [225, 250, 275, 300, 325, 350]\n",
    "\n",
    "for w_size in [5, 8, 10, 12]:\n",
    "    for emb_size in emb_sizes:\n",
    "        print(\"Computing embeddings of size {0} and window {1}...\".format(emb_size, w_size))\n",
    "        model = Word2Vec(sentences, size=emb_size, window=w_size, min_count=5, workers=4)\n",
    "        print(\"Evaluating embeddings of size {0}...\".format(emb_size))\n",
    "        acc, correct_n, incorrect_n = eval_embeddings(model)\n",
    "        print(\"Size {3}; wsize {4}: {0:5.3f} accuracy; Analogies: {1} correct, {2} incorrect\".format(\n",
    "            acc, correct_n, incorrect_n, emb_size, w_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
