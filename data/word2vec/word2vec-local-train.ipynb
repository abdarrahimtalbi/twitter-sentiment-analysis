{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train word2vec locally\n",
    "\n",
    "This allows a smart initialization of our neural net's word embeddings.\n",
    "It seems that initializing the embeddings by training them locally, as opposed to using pre-trained word2vec embeddings (available online) can lead to better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andrei/anaconda3/envs/cil/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN = os.path.join('..', 'train')\n",
    "TEST = os.path.join('..', 'test')\n",
    "POS_TWEET_FILE = os.path.join(TRAIN, 'train_pos_full.txt')\n",
    "NEG_TWEET_FILE = os.path.join(TRAIN, 'train_pos_full.txt')\n",
    "TEST_TWEET_FILE = os.path.join(TEST, 'test_data.txt')\n",
    "EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_tweets(fname):\n",
    "    \"\"\"Read the tweets in the given file.\n",
    "    \n",
    "    Returns a 2d array where every row is a tweet, split into words.\n",
    "    \"\"\"\n",
    "    with open(fname, 'r') as f:\n",
    "        return [l.split() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tweets = read_tweets(POS_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_tweets = read_tweets(NEG_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tweets = read_tweets(TEST_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510000\n"
     ]
    }
   ],
   "source": [
    "sentences = pos_tweets + neg_tweets + test_tweets\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download this for testing: https://github.com/arfon/word2vec/blob/master/questions-words.txt\n",
    "# Highly recommended!\n",
    "\n",
    "question_file = \"questions-words.txt\"\n",
    "\n",
    "def eval_embeddings(model):\n",
    "    accuracy_results = model.accuracy(question_file)\n",
    "    summary = accuracy_results[-1]\n",
    "    assert summary['section'] == 'total'\n",
    "    incorrect = summary['incorrect']\n",
    "    correct = summary['correct']\n",
    "\n",
    "    incorrect_n = len(incorrect)\n",
    "    correct_n = len(correct)\n",
    "\n",
    "    acc = correct_n / incorrect_n\n",
    "    return acc, correct_n, incorrect_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKERS = 8\n",
    "# Note: Moises's team uses size=200 as of June 13.\n",
    "# See: https://groups.google.com/forum/#!msg/gensim/ggCHGncd5rU/Z_pQDD69AAAJ\n",
    "# for some parameter hints.\n",
    "model = Word2Vec(sentences, size=EMBEDDING_SIZE, window=10, min_count=5, workers=WORKERS)# , alpha=0.05, cbow_mean=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Should be queen\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Should be germany\n",
    "model.most_similar(positive=['france', 'berlin'], negative=['paris'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.estimate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A few more sanity checks\n",
    "print(model.similarity('woman', 'man'))\n",
    "print(model.similarity('woman', 'coffee'))\n",
    "print(model.similarity('woman', 'penis'))\n",
    "print(model.similarity('woman', 'football'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(model.similarity('car','man'))\n",
    "print(model.similarity('car','truck'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc, correct_n, incorrect_n = eval_embeddings(model)\n",
    "print(\"{0:5.3f} accuracy; Analogies: {1} correct, {2} incorrect\".format(\n",
    "    acc, correct_n, incorrect_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies (full Twitter data)\n",
    " * Vanilla (size=225, window=5, min_count=5): 0.319 accuracy; Analogies: 2233 correct, 7004 incorrect\n",
    " * (size=300, window=5,  min_count=5): 0.337 accuracy; Analogies: 2329 correct, 6908 incorrect\n",
    " * (size=500, window=5,  min_count=5): 0.330 accuracy; Analogies: 2292 correct, 6945 incorrect\n",
    " * (size=300, window=10, min_count=5): 0.346 accuracy; Analogies: 2374 correct, 6863 incorrect\n",
    " * (size=300, window=15, min_count=5): 0.342 accuracy; Analogies: 2356 correct, 6881 incorrect\n",
    " * (size=400, window=10, min_count=5): 0.341 accuracy; Analogies: 2340 correct, 6870 incorrect\n",
    "\n",
    "### Accuracties (full Twitter data + Nikos 1st stage preprocessing)\n",
    " * (size=200, window=10, min_count=5): 0.327 accuracy; Analogies: 2316 correct, 7093 incorrect\n",
    " * (size=225, window=10, min_count=5): 0.331 accuracy; Analogies: 2342 correct, 7067 incorrect\n",
    " * (size=250, window=10, min_count=5): 0.330 accuracy; Analogies: 2336 correct, 7073 incorrect\n",
    " * (size=275, window=10, min_count=5): 0.337 accuracy; Analogies: 2374 correct, 7035 incorrect\n",
    " * (size=300, window=10, min_count=5): 0.334 accuracy; Analogies: 2355 correct, 7054 incorrect\n",
    " * (size=325, window=10, min_count=5): 0.334 accuracy; Analogies: 2356 correct, 7053 incorrect\n",
    " * (size=350, window=10, min_count=5): 0.330 accuracy; Analogies: 2334 correct, 7075 incorrect\n",
    " * (size=400, window=10, min_count=5): 0.321 accuracy; Analogies: 2289 correct, 7120 incorrect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Embedding dimensionality: {0}\".format(EMBEDDING_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = \"./word2vec-local-gensim-{0}.bin\".format(EMBEDDING_SIZE)\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Some experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings of size 225...\n",
      "Evaluating embeddings of size 225...\n",
      "Size 225: 0.331 accuracy; Analogies: 2342 correct, 7067 incorrect\n",
      "Computing embeddings of size 250...\n",
      "Evaluating embeddings of size 250...\n",
      "Size 250: 0.330 accuracy; Analogies: 2336 correct, 7073 incorrect\n",
      "Computing embeddings of size 275...\n",
      "Evaluating embeddings of size 275...\n",
      "Size 275: 0.337 accuracy; Analogies: 2374 correct, 7035 incorrect\n",
      "Computing embeddings of size 300...\n",
      "Evaluating embeddings of size 300...\n",
      "Size 300: 0.334 accuracy; Analogies: 2355 correct, 7054 incorrect\n",
      "Computing embeddings of size 325...\n",
      "Evaluating embeddings of size 325...\n",
      "Size 325: 0.334 accuracy; Analogies: 2356 correct, 7053 incorrect\n",
      "Computing embeddings of size 350...\n",
      "Evaluating embeddings of size 350...\n",
      "Size 350: 0.330 accuracy; Analogies: 2334 correct, 7075 incorrect\n"
     ]
    }
   ],
   "source": [
    "emb_sizes = [225, 250, 275, 300, 325, 350]\n",
    "\n",
    "for emb_size in emb_sizes:\n",
    "    print(\"Computing embeddings of size {0}...\".format(emb_size))\n",
    "    model = Word2Vec(sentences, size=emb_size, window=10, min_count=5, workers=WORKERS)\n",
    "    print(\"Evaluating embeddings of size {0}...\".format(emb_size))\n",
    "    acc, correct_n, incorrect_n = eval_embeddings(model)\n",
    "    print(\"Size {3}: {0:5.3f} accuracy; Analogies: {1} correct, {2} incorrect\".format(\n",
    "        acc, correct_n, incorrect_n, emb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
