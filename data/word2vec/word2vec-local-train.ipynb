{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train word2vec locally\n",
    "\n",
    "This allows a smart initialization of our neural net's word embeddings.\n",
    "It seems that initializing the embeddings by training them locally, as opposed to using pre-trained word2vec embeddings (available online) can lead to better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andrei/anaconda3/envs/cil/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN = os.path.join('..', 'train')\n",
    "TEST = os.path.join('..', 'test')\n",
    "POS_TWEET_FILE = os.path.join(TRAIN, 'train_pos_full.txt')\n",
    "NEG_TWEET_FILE = os.path.join(TRAIN, 'train_pos_full.txt')\n",
    "TEST_TWEET_FILE = os.path.join(TEST, 'test_data.txt')\n",
    "EMBEDDING_SIZE = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_tweets(fname):\n",
    "    \"\"\"Read the tweets in the given file.\n",
    "    \n",
    "    Returns a 2d array where every row is a tweet, split into words.\n",
    "    \"\"\"\n",
    "    with open(fname, 'r') as f:\n",
    "        return [l.split() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tweets = read_tweets(POS_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_tweets = read_tweets(NEG_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tweets = read_tweets(TEST_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510000\n"
     ]
    }
   ],
   "source": [
    "sentences = pos_tweets + neg_tweets + test_tweets\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download this for testing: https://github.com/arfon/word2vec/blob/master/questions-words.txt\n",
    "# Highly recommended!\n",
    "\n",
    "question_file = \"questions-words.txt\"\n",
    "\n",
    "def eval_embeddings(model):\n",
    "    accuracy_results = model.accuracy(question_file)\n",
    "    summary = accuracy_results[-1]\n",
    "    assert summary['section'] == 'total'\n",
    "    incorrect = summary['incorrect']\n",
    "    correct = summary['correct']\n",
    "\n",
    "    incorrect_n = len(incorrect)\n",
    "    correct_n = len(correct)\n",
    "\n",
    "    acc = correct_n / incorrect_n\n",
    "    return acc, correct_n, incorrect_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKERS = 8\n",
    "# Note: Moises's team uses size=200 as of June 13.\n",
    "# See: https://groups.google.com/forum/#!msg/gensim/ggCHGncd5rU/Z_pQDD69AAAJ\n",
    "# for some parameter hints.\n",
    "model = Word2Vec(sentences, size=EMBEDDING_SIZE, window=10, min_count=5, workers=WORKERS)# , alpha=0.05, cbow_mean=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.48789501190185547),\n",
       " ('madonna', 0.3770555853843689),\n",
       " ('hawk', 0.3623706102371216),\n",
       " ('alpha', 0.353135883808136),\n",
       " ('kenny', 0.3516470193862915),\n",
       " ('sinner', 0.33579689264297485),\n",
       " ('poet', 0.33149391412734985),\n",
       " ('citizen', 0.3234192728996277),\n",
       " ('lawrence', 0.32013171911239624),\n",
       " ('chief', 0.3183271884918213)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be queen\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('croatia', 0.62614506483078),\n",
       " ('germany', 0.5872930288314819),\n",
       " ('spain', 0.586173415184021),\n",
       " ('switzerland', 0.5797890424728394),\n",
       " ('russia', 0.579714298248291),\n",
       " ('finland', 0.5775009393692017),\n",
       " ('belgium', 0.5770790576934814),\n",
       " ('norway', 0.5755430459976196),\n",
       " ('sweden', 0.5712461471557617),\n",
       " ('portugal', 0.5701516270637512)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be germany\n",
    "model.most_similar(positive=['france', 'berlin'], negative=['paris'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'syn0': 111705600,\n",
       " 'syn1neg': 111705600,\n",
       " 'total': 258319200,\n",
       " 'vocab': 34908000}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498196601473\n",
      "0.103336089782\n",
      "0.225357085838\n",
      "0.0123211443995\n"
     ]
    }
   ],
   "source": [
    "# A few more sanity checks\n",
    "print(model.similarity('woman', 'man'))\n",
    "print(model.similarity('woman', 'coffee'))\n",
    "print(model.similarity('woman', 'penis'))\n",
    "print(model.similarity('woman', 'football'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.186135759668\n",
      "0.665023399397\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('car','man'))\n",
    "print(model.similarity('car','truck'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.341 accuracy; Analogies: 2340 correct, 6870 incorrect\n"
     ]
    }
   ],
   "source": [
    "acc, correct_n, incorrect_n = eval_embeddings(model)\n",
    "print(\"{0:5.3f} accuracy; Analogies: {1} correct, {2} incorrect\".format(\n",
    "    acc, correct_n, incorrect_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies (full Twitter data)\n",
    " * Vanilla (size=225, window=5, min_count=5): 0.319 accuracy; Analogies: 2233 correct, 7004 incorrect\n",
    " * (size=300, window=5,  min_count=5): 0.337 accuracy; Analogies: 2329 correct, 6908 incorrect\n",
    " * (size=500, window=5,  min_count=5): 0.330 accuracy; Analogies: 2292 correct, 6945 incorrect\n",
    " * (size=300, window=10, min_count=5): 0.346 accuracy; Analogies: 2374 correct, 6863 incorrect\n",
    " * (size=300, window=15, min_count=5): 0.342 accuracy; Analogies: 2356 correct, 6881 incorrect\n",
    " * (size=400, window=10, min_count=5): 0.341 accuracy; Analogies: 2340 correct, 6870 incorrect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimensionality: 400\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding dimensionality: {0}\".format(EMBEDDING_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = \"./word2vec-local-gensim-{0}.bin\".format(EMBEDDING_SIZE)\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Some experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings of size 100...\n",
      "Evaluating embeddings of size 100...\n",
      "Size 100: 0.274 accuracy; Analogies: 1983 correct, 7227 incorrect\n",
      "Computing embeddings of size 150...\n",
      "Evaluating embeddings of size 150...\n",
      "Size 150: 0.317 accuracy; Analogies: 2216 correct, 6994 incorrect\n",
      "Computing embeddings of size 175...\n",
      "Evaluating embeddings of size 175...\n",
      "Size 175: 0.323 accuracy; Analogies: 2246 correct, 6964 incorrect\n",
      "Computing embeddings of size 200...\n",
      "Evaluating embeddings of size 200...\n",
      "Size 200: 0.337 accuracy; Analogies: 2323 correct, 6887 incorrect\n",
      "Computing embeddings of size 225...\n",
      "Evaluating embeddings of size 225...\n",
      "Size 225: 0.336 accuracy; Analogies: 2316 correct, 6894 incorrect\n",
      "Computing embeddings of size 250...\n",
      "Evaluating embeddings of size 250...\n",
      "Size 250: 0.337 accuracy; Analogies: 2319 correct, 6891 incorrect\n",
      "Computing embeddings of size 275...\n",
      "Evaluating embeddings of size 275...\n",
      "Size 275: 0.346 accuracy; Analogies: 2369 correct, 6841 incorrect\n",
      "Computing embeddings of size 300...\n",
      "Evaluating embeddings of size 300...\n",
      "Size 300: 0.348 accuracy; Analogies: 2376 correct, 6834 incorrect\n",
      "Computing embeddings of size 325...\n",
      "Evaluating embeddings of size 325...\n",
      "Size 325: 0.348 accuracy; Analogies: 2378 correct, 6832 incorrect\n",
      "Computing embeddings of size 350...\n",
      "Evaluating embeddings of size 350...\n",
      "Size 350: 0.343 accuracy; Analogies: 2352 correct, 6858 incorrect\n",
      "Computing embeddings of size 375...\n",
      "Evaluating embeddings of size 375...\n",
      "Size 375: 0.336 accuracy; Analogies: 2318 correct, 6892 incorrect\n",
      "Computing embeddings of size 400...\n",
      "Evaluating embeddings of size 400...\n",
      "Size 400: 0.335 accuracy; Analogies: 2309 correct, 6901 incorrect\n"
     ]
    }
   ],
   "source": [
    "emb_sizes = [100, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400]\n",
    "\n",
    "for emb_size in emb_sizes:\n",
    "    print(\"Computing embeddings of size {0}...\".format(emb_size))\n",
    "    model = Word2Vec(sentences, size=emb_size, window=10, min_count=5, workers=WORKERS)\n",
    "    print(\"Evaluating embeddings of size {0}...\".format(emb_size))\n",
    "    acc, correct_n, incorrect_n = eval_embeddings(model)\n",
    "    print(\"Size {3}: {0:5.3f} accuracy; Analogies: {1} correct, {2} incorrect\".format(\n",
    "        acc, correct_n, incorrect_n, emb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
