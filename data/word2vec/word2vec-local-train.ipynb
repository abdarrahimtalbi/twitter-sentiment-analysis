{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train word2vec locally\n",
    "\n",
    "This allows a smart initialization of our neural net's word embeddings.\n",
    "It seems that initializing the embeddings by training them locally, as opposed to using pre-trained word2vec embeddings (available online) can lead to better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andrei/anaconda3/envs/cil/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN = os.path.join('..', 'train')\n",
    "TEST = os.path.join('..', 'test')\n",
    "POS_TWEET_FILE = os.path.join(TRAIN, 'train_pos_full.txt')\n",
    "NEG_TWEET_FILE = os.path.join(TRAIN, 'train_pos_full.txt')\n",
    "TEST_TWEET_FILE = os.path.join(TEST, 'test_data.txt')\n",
    "EMBEDDING_SIZE = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_tweets(fname):\n",
    "    \"\"\"Read the tweets in the given file.\n",
    "    \n",
    "    Returns a 2d array where every row is a tweet, split into words.\n",
    "    \"\"\"\n",
    "    with open(fname, 'r') as f:\n",
    "        return [l.split() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tweets = read_tweets(POS_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_tweets = read_tweets(NEG_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tweets = read_tweets(TEST_TWEET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510000\n"
     ]
    }
   ],
   "source": [
    "sentences = pos_tweets + neg_tweets + test_tweets\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download this for testing: https://github.com/arfon/word2vec/blob/master/questions-words.txt\n",
    "# Highly recommended!\n",
    "\n",
    "question_file = \"questions-words.txt\"\n",
    "\n",
    "def eval_embeddings(model):\n",
    "    accuracy_results = model.accuracy(question_file)\n",
    "    summary = accuracy_results[-1]\n",
    "    assert summary['section'] == 'total'\n",
    "    incorrect = summary['incorrect']\n",
    "    correct = summary['correct']\n",
    "\n",
    "    incorrect_n = len(incorrect)\n",
    "    correct_n = len(correct)\n",
    "\n",
    "    acc = correct_n / incorrect_n\n",
    "    return acc, correct_n, incorrect_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKERS = 8\n",
    "# Note: Moises's team uses size=200 as of June 13.\n",
    "# See: https://groups.google.com/forum/#!msg/gensim/ggCHGncd5rU/Z_pQDD69AAAJ\n",
    "# for some parameter hints.\n",
    "model = Word2Vec(sentences, size=EMBEDDING_SIZE, window=10, min_count=5, workers=WORKERS)# , alpha=0.05, cbow_mean=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.480918288230896),\n",
       " ('alpha', 0.384929895401001),\n",
       " ('madonna', 0.3734423816204071),\n",
       " ('lawrence', 0.3621298670768738),\n",
       " ('protects', 0.3620363771915436),\n",
       " ('poet', 0.3521104156970978),\n",
       " ('hawk', 0.34590622782707214),\n",
       " ('child', 0.3413478136062622),\n",
       " ('kenny', 0.34024181962013245),\n",
       " ('sinner', 0.3332200050354004)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be queen\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('croatia', 0.598901629447937),\n",
       " ('sweden', 0.5939220190048218),\n",
       " ('switzerland', 0.5885233283042908),\n",
       " ('norway', 0.5879368782043457),\n",
       " ('belgium', 0.5865507125854492),\n",
       " ('finland', 0.5794695019721985),\n",
       " ('holland', 0.5722660422325134),\n",
       " ('germany', 0.5641714334487915),\n",
       " ('italy', 0.5595147609710693),\n",
       " ('canada', 0.5537332892417908)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be germany\n",
    "model.most_similar(positive=['france', 'berlin'], negative=['paris'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'syn0': 97742400, 'syn1neg': 97742400, 'total': 230392800, 'vocab': 34908000}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.519508487089\n",
      "0.0890147546286\n",
      "0.229477331801\n",
      "0.0278565673937\n"
     ]
    }
   ],
   "source": [
    "# A few more sanity checks\n",
    "print(model.similarity('woman', 'man'))\n",
    "print(model.similarity('woman', 'coffee'))\n",
    "print(model.similarity('woman', 'penis'))\n",
    "print(model.similarity('woman', 'football'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.197424738269\n",
      "0.698331116458\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('car','man'))\n",
    "print(model.similarity('car','truck'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.335 accuracy; Analogies: 2340 correct, 6992 incorrect\n"
     ]
    }
   ],
   "source": [
    "acc, correct_n, incorrect_n = eval_embeddings(model)\n",
    "print(\"{0:5.3f} accuracy; Analogies: {1} correct, {2} incorrect\".format(\n",
    "    acc, correct_n, incorrect_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies (full Twitter data)\n",
    " * Vanilla (size=225, window=5, min_count=5): 0.319 accuracy; Analogies: 2233 correct, 7004 incorrect\n",
    " * (size=300, window=5,  min_count=5): 0.337 accuracy; Analogies: 2329 correct, 6908 incorrect\n",
    " * (size=500, window=5,  min_count=5): 0.330 accuracy; Analogies: 2292 correct, 6945 incorrect\n",
    " * (size=300, window=10, min_count=5): 0.346 accuracy; Analogies: 2374 correct, 6863 incorrect\n",
    " * (size=300, window=15, min_count=5): 0.342 accuracy; Analogies: 2356 correct, 6881 incorrect\n",
    " * (size=400, window=10, min_count=5): 0.341 accuracy; Analogies: 2340 correct, 6870 incorrect\n",
    "\n",
    "### Accuracties (full Twitter data + Nikos 1st stage preprocessing)\n",
    " * (size=200, window=10, min_count=5): 0.327 accuracy; Analogies: 2316 correct, 7093 incorrect\n",
    " * (size=225, window=10, min_count=5): 0.331 accuracy; Analogies: 2342 correct, 7067 incorrect\n",
    " * (size=250, window=10, min_count=5): 0.330 accuracy; Analogies: 2336 correct, 7073 incorrect\n",
    " * (size=275, window=10, min_count=5): 0.337 accuracy; Analogies: 2374 correct, 7035 incorrect\n",
    " * (size=300, window=10, min_count=5): 0.334 accuracy; Analogies: 2355 correct, 7054 incorrect\n",
    " * (size=325, window=10, min_count=5): 0.334 accuracy; Analogies: 2356 correct, 7053 incorrect\n",
    " * (size=350, window=10, min_count=5): 0.330 accuracy; Analogies: 2334 correct, 7075 incorrect\n",
    " * (size=400, window=10, min_count=5): 0.321 accuracy; Analogies: 2289 correct, 7120 incorrect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimensionality: 350\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding dimensionality: {0}\".format(EMBEDDING_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing embeddings to file ./word2vec-local-gensim-350.bin.\n"
     ]
    }
   ],
   "source": [
    "fname = \"./word2vec-local-gensim-{0}.bin\".format(EMBEDDING_SIZE)\n",
    "print(\"Writing embeddings to file {0}.\".format(fname))\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Some experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emb_sizes = [225, 250, 275, 300, 325, 350]\n",
    "\n",
    "for emb_size in emb_sizes:\n",
    "    print(\"Computing embeddings of size {0}...\".format(emb_size))\n",
    "    model = Word2Vec(sentences, size=emb_size, window=10, min_count=5, workers=WORKERS)\n",
    "    print(\"Evaluating embeddings of size {0}...\".format(emb_size))\n",
    "    acc, correct_n, incorrect_n = eval_embeddings(model)\n",
    "    print(\"Size {3}: {0:5.3f} accuracy; Analogies: {1} correct, {2} incorrect\".format(\n",
    "        acc, correct_n, incorrect_n, emb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
